{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def pool_forward(A_prev, hparameters, mode):\n", "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n", "    f = hparameters[\"f\"]\n", "    stride = hparameters[\"stride\"]\n", "    \n", "    n_H = int(1 + (n_H_prev - f) / stride)\n", "    n_W = int(1 + (n_W_prev - f) / stride)\n", "    n_C = n_C_prev\n", "    A = np.zeros((m, n_H, n_W, n_C))      \n", "    for h in range(n_H):                      # loop on the vertical axis of the output volume\n", "        for w in range(n_W):                  # loop on the horizontal axis of the output volume\n", "            # Use the corners to define the current slice on the ith training example of A_prev, channel c\n", "            A_prev_slice = A_prev[:, h*stride:h*stride+f, w*stride:w*stride+f, :]  \n", "            # Compute the pooling operation on the slice. Use an if statment to differentiate the modes. \n", "            if mode == \"max\":\n", "                A[:, h, w, :] = np.max(A_prev_slice, axis=(1,2))\n", "            elif mode == \"average\":\n", "                A[:, h, w, :] = np.average(A_prev_slice, axis=(1,2))\n", "    cache = (A_prev, hparameters)\n", "    assert(A.shape == (m, n_H, n_W, n_C))\n", "    return A, cache"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def pool_backward(dA, cache, mode):\n", "    \"\"\"\n", "    Implements the backward pass of the pooling layer\n", "    \n", "    Arguments:\n", "    dA -- gradient of cost with respect to the output of the pooling layer, same shape as A\n", "    cache -- cache output from the forward pass of the pooling layer, contains the layer's input and hparameters \n", "    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n", "    \n", "    Returns:\n", "    dA_prev -- gradient of cost with respect to the input of the pooling layer, same shape as A_prev\n", "    \"\"\"\n", "    (A_prev, hparameters) = cache\n", "    \n", "    stride = hparameters[\"stride\"]\n", "    f = hparameters[\"f\"]\n", "    m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape #256,28,28,6\n", "    m, n_H, n_W, n_C = dA.shape                    #256,14,14,6\n", "    \n", "    dA_prev = np.zeros((m, n_H_prev, n_W_prev, n_C_prev)) #256,28,28,6\n", "        \n", "    for h in range(n_H):                    # loop on the vertical axis\n", "        for w in range(n_W):                # loop on the horizontal axis\n", "            # Find the corners of the current \"slice\"\n", "            vert_start, horiz_start  = h*stride, w*stride\n", "            vert_end,   horiz_end    = vert_start+f, horiz_start+f\n", "            \n", "            # Compute the backward propagation in both modes.\n", "            if mode == \"max\":\n", "                A_prev_slice = A_prev[:, vert_start: vert_end, horiz_start: horiz_end, :] \n", "                A_prev_slice = np.transpose(A_prev_slice, (1,2,3,0))\n", "                mask = A_prev_slice==A_prev_slice.max((0,1))           \n", "                mask = np.transpose(mask, (3,2,0,1))                   \n", "                dA_prev[:, vert_start: vert_end, horiz_start: horiz_end, :] \\\n", "                      += np.transpose(np.multiply(dA[:, h, w, :][:,:,np.newaxis,np.newaxis],mask), (0,2,3,1))\n", "            elif mode == \"average\":\n", "                da = dA[:, h, w, :][:,np.newaxis,np.newaxis,:]  #256*1*1*6\n", "                dA_prev[:, vert_start: vert_end, horiz_start: horiz_end, :] += np.repeat(np.repeat(da, 2, axis=1), 2, axis=2)/f/f\n", "    \n", "    assert(dA_prev.shape == A_prev.shape)\n", "    return dA_prev"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def subsampling_forward(A_prev, weight, b, hparameters):\n", "    A_, cache = pool_forward(A_prev, hparameters, 'average') \n", "    A = A_ * weight + b\n", "    cache_A = (cache, A_)\n", "    return A, cache_A_"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def subsampling_backward(dA, weight, b, cache_A_):\n", "    (cache, A_) = cache_A_\n", "    db = dA\n", "    dW = np.sum(np.multiply(dA, A_))\n", "    dA_ = dA * weight\n", "    dA_prev = pool_backward(dA_, cache, 'average') \n", "    return dA_prev, dW, db"]}, {"cell_type": "markdown", "metadata": {}, "source": ["################################# functions below are NOT USED in training ################################################"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def pool_forward_orig(A_prev, hparameters, mode = \"max\"):\n", "    \"\"\"\n", "    Implements the forward pass of the pooling layer\n", "    \n", "    Arguments:\n", "    A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n", "    hparameters -- python dictionary containing \"f\" and \"stride\"\n", "    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n", "    \n", "    Returns:\n", "    A -- output of the pool layer, a numpy array of shape (m, n_H, n_W, n_C)\n", "    cache -- cache used in the backward pass of the pooling layer, contains the input and hparameters \n", "    \"\"\"\n", "    # Retrieve dimensions from the input shape\n", "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n", "    \n", "    # Retrieve hyperparameters from \"hparameters\"\n", "    f = hparameters[\"f\"]\n", "    stride = hparameters[\"stride\"]\n", "    \n", "    # Define the dimensions of the output\n", "    n_H = int(1 + (n_H_prev - f) / stride)\n", "    n_W = int(1 + (n_W_prev - f) / stride)\n", "    n_C = n_C_prev\n", "    \n", "    # Initialize output matrix A\n", "    A = np.zeros((m, n_H, n_W, n_C))              \n", "    \n", "    for i in range(m):                            # loop over the training examples\n", "        for h in range(n_H):                      # loop on the vertical axis of the output volume\n", "            for w in range(n_W):                  # loop on the horizontal axis of the output volume\n", "                for c in range (n_C):             # loop over the channels of the output volume\n", "                    \n", "                    # Find the corners of the current \"slice\" \n", "                    vert_start  = h*stride\n", "                    vert_end    = vert_start+f\n", "                    horiz_start = w*stride\n", "                    horiz_end   = horiz_start+f\n", "                    \n", "                    # Use the corners to define the current slice on the ith training example of A_prev, channel c.\n", "                    a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end, c]\n", "                    \n", "                    # Compute the pooling operation on the slice. Use an if statment to differentiate the modes. \n", "                    if mode == \"max\":\n", "                        A[i, h, w, c] = np.max(a_prev_slice)\n", "                    elif mode == \"average\":\n", "                        A[i, h, w, c] = np.average(a_prev_slice)\n", "    \n", "    # Store the input and hparameters in \"cache\" for pool_backward()\n", "    cache = (A_prev, hparameters)\n", "    \n", "    # Making sure your output shape is correct\n", "    assert(A.shape == (m, n_H, n_W, n_C))\n", "    \n", "    return A, cache"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def create_mask_from_window(x):\n", "    \"\"\"\n", "    Creates a mask from an input matrix x, to identify the max entry of x.\n", "    \n", "    Arguments:\n", "    x -- Array of shape (f, f)\n", "    \n", "    Returns:\n", "    mask -- Array of the same shape as window, contains a True at the position corresponding to the max entry of x.\n", "    \"\"\"\n", "    mask = x==np.max(x) \n", "    return mask"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def distribute_value(dz, shape):\n", "    \"\"\"\n", "    Distributes the input value in the matrix of dimension shape\n", "    \n", "    Arguments:\n", "    dz -- input scalar\n", "    shape -- the shape (n_H, n_W) of the output matrix for which we want to distribute the value of dz\n", "    \n", "    Returns:\n", "    a -- Array of size (n_H, n_W) for which we distributed the value of dz\n", "    \"\"\"\n", "    (n_H, n_W) = shape\n", "    a = np.ones(shape) * dz/n_H/n_W\n", "    return a"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def pool_backward_orig(dA, cache, mode = \"max\"):\n", "    \"\"\"\n", "    Implements the backward pass of the pooling layer\n", "    \n", "    Arguments:\n", "    dA -- gradient of cost with respect to the output of the pooling layer, same shape as A\n", "    cache -- cache output from the forward pass of the pooling layer, contains the layer's input and hparameters \n", "    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n", "    \n", "    Returns:\n", "    dA_prev -- gradient of cost with respect to the input of the pooling layer, same shape as A_prev\n", "    \"\"\"\n", "    # Retrieve information from cache \n", "    (A_prev, hparameters) = cache\n", "    \n", "    # Retrieve hyperparameters from \"hparameters\"\n", "    stride = hparameters[\"stride\"]\n", "    f = hparameters[\"f\"]\n", "    \n", "    # Retrieve dimensions from A_prev's shape and dA's shape\n", "    m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape\n", "    m, n_H, n_W, n_C = dA.shape\n", "    \n", "    # Initialize dA_prev with zeros\n", "    dA_prev = np.zeros((m, n_H_prev, n_W_prev, n_C_prev))\n", "    \n", "    for i in range(m):                          # loop over the training examples\n", "        \n", "        # select training example from A_prev \n", "        a_prev = A_prev[i, :, :, :]\n", "        \n", "        for h in range(n_H):                    # loop on the vertical axis\n", "            for w in range(n_W):                # loop on the horizontal axis\n", "                for c in range(n_C):            # loop over the channels (depth)\n", "                    \n", "                    # Find the corners of the current \"slice\" \n", "                    vert_start  = h*stride\n", "                    vert_end    = vert_start+f\n", "                    horiz_start = w*stride\n", "                    horiz_end   = horiz_start+f\n", "                    \n", "                    # Compute the backward propagation in both modes.\n", "                    if mode == \"max\":\n", "                        \n", "                        # Use the corners and \"c\" to define the current slice from a_prev (\u00e2\u2030\u02c61 line)\n", "                        a_prev_slice = a_prev[vert_start:vert_end, horiz_start:horiz_end, c]\n", "                        # Create the mask from a_prev_slice (\u00e2\u2030\u02c61 line)\n", "                        mask = create_mask_from_window(a_prev_slice)\n", "                        # Set dA_prev to be dA_prev + (the mask multiplied by the correct entry of dA) (\u00e2\u2030\u02c61 line)\n", "                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += np.multiply(mask, dA[i, h, w, c])\n", "                        \n", "                    elif mode == \"average\":\n", "                        \n", "                        # Get the value a from dA \n", "                        da = dA[i, h, w, c]\n", "                        # Define the shape of the filter as fxf \n", "                        shape = (f, f)\n", "                        # Distribute it to get the correct slice of dA_prev. i.e. Add the distributed value of da. \n", "                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += distribute_value(da, shape)\n", "    \n", "    # Making sure your output shape is correct\n", "    assert(dA_prev.shape == A_prev.shape)\n", "    \n", "    return dA_prev"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}